{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc7f54c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this project is to predict, based on customer behavior and account properties, whether a customer will leave the bank. The effectiveness of the predictions will be measured through the F1 score, which is a way of measuring the ability to correctly predict the exact number of customers that exited. I've chosen CatBoost as the model for its ability to work with both numeric and categorical features, as well as its built-in ability to fix class imbalance through two different methods. I'll first optimize a model with the original class balance. I'll then optimize a 2nd model where the two CatBoost class-weighting options are available as parameters. I'll then select the model with the best F1 score in order to evaluate it on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d58048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna, json\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d15e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_info(df, head_cnt=10):\n",
    "    df.info(memory_usage=False)\n",
    "    print(\"\\n\")\n",
    "    display(df.head(head_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b57315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"Churn.csv\")\n",
    "custom_info(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cabefef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber: 1 to 10000 with 10000 unique values\n",
      "CustomerId: 15565701 to 15815690 with 10000 unique values\n",
      "Surname: Abazu to Zuyeva with 2932 unique values\n",
      "CreditScore: 350 to 850 with 460 unique values\n",
      "Geography: France to Spain with 3 unique values\n",
      "Gender: Female to Male with 2 unique values\n",
      "Age: 18 to 92 with 70 unique values\n",
      "Tenure: 0.0 to 10.0 with 11 unique values\n",
      "Balance: 0.0 to 250898.09 with 6382 unique values\n",
      "NumOfProducts: 1 to 4 with 4 unique values\n",
      "HasCrCard: 0 to 1 with 2 unique values\n",
      "IsActiveMember: 0 to 1 with 2 unique values\n",
      "EstimatedSalary: 11.58 to 199992.48 with 9999 unique values\n",
      "Exited: 0 to 1 with 2 unique values\n",
      "\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect range and unique value count of each column\n",
    "for col in all_data.columns:\n",
    "    col_min = all_data[col].min()\n",
    "    col_max = all_data[col].max()\n",
    "    unq_val = all_data[col].nunique()\n",
    "    print(f\"{col}: {col_min} to {col_max} with {unq_val} unique values\")\n",
    "    \n",
    "# Inspect the target class-balance\n",
    "print(f\"\\n{all_data['Exited'].value_counts()}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ceb4b",
   "metadata": {},
   "source": [
    "About 20% of the targets is a customer that exited. When it comes to training the model, I don't see a use for RowNumber, CustomerId, and Surname. I'll drop those when creating the DF composed of the features. I'll create categorical versions of \"Tenure\" and \"NumOfProducts\" in order to provide the model with feature variations that do not assume a relevance to the numerical order. \n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Convert \"Geography\" and \"Gender\" to categorical.\n",
    "- Create additional feature where \"Tenure\" is categorical and missing values are converted to an \"unknown\" category.\n",
    "- Create additional \"NumOfProducts\" feature that's categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650cac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical version of \"Tenure\"\n",
    "all_data['TenureCAT'] = all_data['Tenure'].apply(\n",
    "    lambda x: 'unknown' if pd.isna(x) else str(int(x))).astype('category')\n",
    "\n",
    "all_data['Geography'] = all_data['Geography'].astype('category')\n",
    "all_data['Gender'] = all_data['Gender'].astype('category')\n",
    "all_data['NumOfProductsCAT'] = all_data['NumOfProducts'].astype('category')\n",
    "\n",
    "# Store list of categorical features for CatBoost\n",
    "cat_feat = ['Geography', 'Gender', 'TenureCAT', 'NumOfProductsCAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987e39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (6000, 12) (2000, 12) (2000, 12)\n",
      "Class Count: [4777 1223] [1593  407] [1593  407]\n"
     ]
    }
   ],
   "source": [
    "# Set up training, validation, and test set\n",
    "RND = 12345\n",
    "\n",
    "X = all_data.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Exited'])\n",
    "y = all_data['Exited'].copy()\n",
    "\n",
    "# First divide into training/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=RND\n",
    ")\n",
    "\n",
    "# Divide training set into training/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, stratify=y_train, random_state=RND\n",
    ") # The result is a 60/20/20 set\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Class Count:\", np.bincount(y_train), np.bincount(y_val), np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d2d12",
   "metadata": {},
   "source": [
    "## 1. Model Optimization (Untouched Class Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8ff10d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-29 00:33:09,696] A new study created in memory with name: no-name-b42074ba-4767-4f29-984c-8d3e66d43a4e\n",
      "[I 2025-08-29 00:34:18,543] Trial 1 finished with value: 0.6268260292164675 and parameters: {'depth': 3, 'learning_rate': 0.0511288346565954, 'iterations': 2751, 'l2_leaf_reg': 1.3408918054255857e-06}. Best is trial 1 with value: 0.6268260292164675.\n",
      "[I 2025-08-29 00:34:50,440] Trial 3 finished with value: 0.6605504587155964 and parameters: {'depth': 5, 'learning_rate': 0.0026745390456811772, 'iterations': 2389, 'l2_leaf_reg': 0.00021036796895770125}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:35:05,222] Trial 0 finished with value: 0.6576354679802955 and parameters: {'depth': 5, 'learning_rate': 0.005941573406081425, 'iterations': 2833, 'l2_leaf_reg': 4.784528155668776e-06}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:35:36,130] Trial 4 finished with value: 0.6319612590799033 and parameters: {'depth': 6, 'learning_rate': 0.011935959891038479, 'iterations': 2816, 'l2_leaf_reg': 3.916259043448626e-06}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:35:52,590] Trial 5 finished with value: 0.5835294117647059 and parameters: {'depth': 5, 'learning_rate': 0.09552496688884125, 'iterations': 2233, 'l2_leaf_reg': 9.228422160119415e-06}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:36:15,874] Trial 2 finished with value: 0.6138613861386139 and parameters: {'depth': 8, 'learning_rate': 0.020838009600750898, 'iterations': 2759, 'l2_leaf_reg': 0.00014180359307724711}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:36:51,137] Trial 6 finished with value: 0.6542261251372118 and parameters: {'depth': 7, 'learning_rate': 0.003655607342988871, 'iterations': 2068, 'l2_leaf_reg': 0.0004036694656528097}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:36:57,420] Trial 8 finished with value: 0.6566791510611735 and parameters: {'depth': 4, 'learning_rate': 0.013567893021770102, 'iterations': 2172, 'l2_leaf_reg': 0.00019934165845152794}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:37:59,510] Trial 7 finished with value: 0.6194926568758345 and parameters: {'depth': 8, 'learning_rate': 0.01500157284927728, 'iterations': 2603, 'l2_leaf_reg': 1.651661443574054e-06}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:38:04,422] Trial 12 finished with value: 0.6528117359413204 and parameters: {'depth': 3, 'learning_rate': 0.031285170906421605, 'iterations': 2407, 'l2_leaf_reg': 0.0012639323557766282}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:38:30,781] Trial 10 finished with value: 0.6111771700356718 and parameters: {'depth': 6, 'learning_rate': 0.04585459907866955, 'iterations': 2589, 'l2_leaf_reg': 1.466445062711567e-06}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:38:41,419] Trial 9 finished with value: 0.6428571428571429 and parameters: {'depth': 7, 'learning_rate': 0.00816125597174469, 'iterations': 2872, 'l2_leaf_reg': 4.281401634575235e-05}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:39:24,103] Trial 11 finished with value: 0.6384522370012092 and parameters: {'depth': 7, 'learning_rate': 0.008045298717218215, 'iterations': 2790, 'l2_leaf_reg': 9.965832734552539e-05}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:39:38,929] Trial 14 finished with value: 0.6595995288574795 and parameters: {'depth': 6, 'learning_rate': 0.0013409436882109009, 'iterations': 2386, 'l2_leaf_reg': 0.007951244207096446}. Best is trial 3 with value: 0.6605504587155964.\n",
      "[I 2025-08-29 00:39:46,277] Trial 13 finished with value: 0.6063977746870655 and parameters: {'depth': 8, 'learning_rate': 0.016144302661367477, 'iterations': 2201, 'l2_leaf_reg': 9.29036045298262e-05}. Best is trial 3 with value: 0.6605504587155964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OPTIMIZED MODEL (Untouched Class Balance)\n",
      "\n",
      "Parameters:\n",
      "  depth: 5\n",
      "  learning_rate: 0.002675\n",
      "  iterations: 2389\n",
      "  l2_leaf_reg: 0.000210\n",
      "\n",
      "Threshold: 0.2800\n",
      "F1: 0.6606\n",
      "AUC-ROC: 0.8847\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS = 15 # Each trial trains a CatBoost model\n",
    "# Find the best threshold for each candidate\n",
    "thresholds = np.linspace(0.0, 0.75, 76)\n",
    "\n",
    "def objective(trial):\n",
    "    # Parameters to optimize\n",
    "    depth = trial.suggest_int(\"depth\", 3, 8)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True)\n",
    "    iterations = trial.suggest_int(\"iterations\", 2000, 3000)\n",
    "    l2_leaf_reg = trial.suggest_float(\"l2_leaf_reg\", 0.000001, 0.01, log=True)\n",
    "\n",
    "    # Build CatBoost model with current parameters\n",
    "    model = CatBoostClassifier(\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        iterations=iterations,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        random_seed=RND,\n",
    "        verbose=False,\n",
    "        thread_count=-1\n",
    "    )\n",
    "\n",
    "    # Fit on training set\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        cat_features=cat_feat       \n",
    "    )\n",
    "\n",
    "    # Calculate model probabilities for validation set\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Find best threshold according to F1 score\n",
    "    best_t, f1 = 0.5, -1.0\n",
    "    for t in thresholds:\n",
    "        # Convert probs to binary predictions based on threshold\n",
    "        pred = (val_proba >= t).astype(int)\n",
    "        f = f1_score(y_val, pred)\n",
    "        if f > f1:\n",
    "            f1 = f\n",
    "            best_t = float(t)\n",
    "\n",
    "    # Store best threshold for this candidate\n",
    "    trial.set_user_attr(\"best_threshold\", best_t)  \n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Run Optuna optimization\n",
    "sampler = optuna.samplers.TPESampler(seed=RND)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=N_TRIALS, n_jobs=5)\n",
    "\n",
    "# Store optimized parameters\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params.copy()\n",
    "best_threshold = float(best_trial.user_attrs.get(\"best_threshold\"))\n",
    "\n",
    "# Rebuild best model along with its probs and predictions\n",
    "best_model = CatBoostClassifier(\n",
    "    depth=int(best_params[\"depth\"]),\n",
    "    learning_rate=float(best_params[\"learning_rate\"]),\n",
    "    iterations=int(best_params[\"iterations\"]),\n",
    "    l2_leaf_reg=float(best_params[\"l2_leaf_reg\"]),\n",
    "    random_seed=RND,\n",
    "    verbose=False,\n",
    "    thread_count=-1\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train, \n",
    "    cat_features=cat_feat       \n",
    ")\n",
    "\n",
    "val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "val_pred = (val_proba >= best_threshold).astype(int)\n",
    "final_f1 = f1_score(y_val, val_pred)\n",
    "final_auc = roc_auc_score(y_val, val_proba)\n",
    "\n",
    "print(\"\\nOPTIMIZED MODEL (Untouched Class Balance)\\n\")\n",
    "\n",
    "print(\"Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")\n",
    "        \n",
    "print(f\"\\nThreshold: {best_threshold:.4f}\")\n",
    "print(f\"F1: {final_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {final_auc.round(4)}\")\n",
    "\n",
    "# Store model in order to compare with best auto-balanced model\n",
    "best_model.save_model(\"best_unbalanced.cbm\")\n",
    "meta = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": best_threshold,\n",
    "    \"val_f1\": final_f1,\n",
    "    \"val_auc\": final_auc\n",
    "}\n",
    "with open(\"best_unbalanced_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805fba3a",
   "metadata": {},
   "source": [
    "## 2. Model Optimization (CatBoost Auto Class Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a491233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-29 00:40:38,591] A new study created in memory with name: no-name-a6f5cc7e-c8ae-4492-a03f-66c4fe8d1517\n",
      "[I 2025-08-29 00:42:17,183] Trial 1 finished with value: 0.635561160151324 and parameters: {'depth': 4, 'learning_rate': 0.01529676403069316, 'iterations': 2885, 'l2_leaf_reg': 2.197490206432143e-05, 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.635561160151324.\n",
      "[I 2025-08-29 00:42:39,749] Trial 0 finished with value: 0.6599326599326599 and parameters: {'depth': 7, 'learning_rate': 0.0028540296513652956, 'iterations': 2108, 'l2_leaf_reg': 0.004750829383251104, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:42:50,991] Trial 4 finished with value: 0.6313193588162762 and parameters: {'depth': 7, 'learning_rate': 0.01622841125866564, 'iterations': 2123, 'l2_leaf_reg': 1.859046057989532e-05, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:42:58,666] Trial 2 finished with value: 0.6537585421412301 and parameters: {'depth': 8, 'learning_rate': 0.001901230965941459, 'iterations': 2319, 'l2_leaf_reg': 0.0006034462175324824, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:43:35,562] Trial 3 finished with value: 0.6291834002677376 and parameters: {'depth': 8, 'learning_rate': 0.017446114352953176, 'iterations': 2501, 'l2_leaf_reg': 3.733834297042732e-06, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:43:48,177] Trial 5 finished with value: 0.6446499339498019 and parameters: {'depth': 4, 'learning_rate': 0.010875292509436071, 'iterations': 2798, 'l2_leaf_reg': 0.00028899176295137623, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:44:12,497] Trial 8 finished with value: 0.6110429447852761 and parameters: {'depth': 4, 'learning_rate': 0.09581070253813628, 'iterations': 2149, 'l2_leaf_reg': 9.365231649895034e-05, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:44:33,692] Trial 9 finished with value: 0.6330275229357798 and parameters: {'depth': 3, 'learning_rate': 0.06066103672308378, 'iterations': 2041, 'l2_leaf_reg': 0.0014027190922588533, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:44:49,640] Trial 6 finished with value: 0.6585365853658537 and parameters: {'depth': 8, 'learning_rate': 0.0038608997406569803, 'iterations': 2038, 'l2_leaf_reg': 0.009941644084332416, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:45:28,945] Trial 7 finished with value: 0.6541019955654103 and parameters: {'depth': 7, 'learning_rate': 0.003652266023712062, 'iterations': 2760, 'l2_leaf_reg': 0.0032570936535887903, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:45:40,959] Trial 11 finished with value: 0.6438529784537389 and parameters: {'depth': 5, 'learning_rate': 0.014675855495132272, 'iterations': 2098, 'l2_leaf_reg': 0.004981217137006667, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.6599326599326599.\n",
      "[I 2025-08-29 00:45:44,355] Trial 10 finished with value: 0.6615776081424936 and parameters: {'depth': 5, 'learning_rate': 0.006143977606332298, 'iterations': 2897, 'l2_leaf_reg': 2.8247969032742353e-06, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 10 with value: 0.6615776081424936.\n",
      "[I 2025-08-29 00:46:28,960] Trial 12 finished with value: 0.6157894736842106 and parameters: {'depth': 7, 'learning_rate': 0.0217414252340024, 'iterations': 2129, 'l2_leaf_reg': 0.0003282612674326098, 'auto_class_weights': 'Balanced'}. Best is trial 10 with value: 0.6615776081424936.\n",
      "[I 2025-08-29 00:46:31,218] Trial 13 finished with value: 0.6550218340611355 and parameters: {'depth': 7, 'learning_rate': 0.002864157458816004, 'iterations': 2159, 'l2_leaf_reg': 5.69376787041498e-06, 'auto_class_weights': 'Balanced'}. Best is trial 10 with value: 0.6615776081424936.\n",
      "[I 2025-08-29 00:46:56,532] Trial 14 finished with value: 0.659698025551684 and parameters: {'depth': 6, 'learning_rate': 0.001247681737409242, 'iterations': 2527, 'l2_leaf_reg': 0.007792628572071647, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 10 with value: 0.6615776081424936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL MODEL (CatBoost Auto Class Weight)\n",
      "\n",
      "\n",
      "Parameters:\n",
      "  depth: 5\n",
      "  learning_rate: 0.006144\n",
      "  iterations: 2897\n",
      "  l2_leaf_reg: 0.000003\n",
      "  auto_class_weights: SqrtBalanced\n",
      "\n",
      "Threshold: 0.4900\n",
      "F1: 0.6616\n",
      "AUC-ROC: 0.8773\n"
     ]
    }
   ],
   "source": [
    "# The only difference in this set up is that the two parameters from \n",
    "# auto_class_weights will be available to the optimizer\n",
    "\n",
    "def objective(trial):\n",
    "    # Parameters to optimize\n",
    "    depth = trial.suggest_int(\"depth\", 3, 8)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True)\n",
    "    iterations = trial.suggest_int(\"iterations\", 2000, 3000)\n",
    "    l2_leaf_reg = trial.suggest_float(\"l2_leaf_reg\", 0.000001, 0.01, log=True)\n",
    "    auto_class_weights = trial.suggest_categorical(\"auto_class_weights\", [\"Balanced\", \"SqrtBalanced\"])\n",
    "\n",
    "    # Build CatBoost model with current parameters\n",
    "    model = CatBoostClassifier(\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        iterations=iterations,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        auto_class_weights=auto_class_weights,\n",
    "        random_seed=RND,\n",
    "        verbose=False,\n",
    "        thread_count=-1\n",
    "    )\n",
    "\n",
    "    # Fit on training set\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        cat_features=cat_feat       \n",
    "    )\n",
    "\n",
    "    # Calculate model probabilities for validation set\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Find best threshold according to F1 score\n",
    "    best_t, f1 = 0.5, -1.0\n",
    "    for t in thresholds:\n",
    "        # Convert probs to binary predictions based on threshold\n",
    "        pred = (val_proba >= t).astype(int)\n",
    "        f = f1_score(y_val, pred)\n",
    "        if f > f1:\n",
    "            f1 = f\n",
    "            best_t = float(t)\n",
    "\n",
    "    # Store best threshold for this candidate\n",
    "    trial.set_user_attr(\"best_threshold\", best_t)  \n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Run Optuna optimization\n",
    "sampler = optuna.samplers.TPESampler(seed=RND)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=N_TRIALS, n_jobs=5)\n",
    "\n",
    "# Retrieve optimized parameters\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params.copy()\n",
    "best_threshold = float(best_trial.user_attrs.get(\"best_threshold\"))\n",
    "\n",
    "# Rebuild best model along with its probs and predictions\n",
    "best_model = CatBoostClassifier(\n",
    "    depth=int(best_params[\"depth\"]),\n",
    "    learning_rate=float(best_params[\"learning_rate\"]),\n",
    "    iterations=int(best_params[\"iterations\"]),\n",
    "    l2_leaf_reg=float(best_params[\"l2_leaf_reg\"]),\n",
    "    auto_class_weights=best_params[\"auto_class_weights\"],\n",
    "    random_seed=RND,\n",
    "    verbose=False,\n",
    "    thread_count=-1\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train, \n",
    "    cat_features=cat_feat       \n",
    ")\n",
    "\n",
    "val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "val_pred = (val_proba >= best_threshold).astype(int)\n",
    "final_f1 = f1_score(y_val, val_pred)\n",
    "final_auc = roc_auc_score(y_val, val_proba)\n",
    "\n",
    "print(\"\\nFINAL MODEL (CatBoost Auto Class Weight)\\n\")\n",
    "\n",
    "print(\"\\nParameters:\")\n",
    "for k, v in best_params.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")\n",
    "        \n",
    "print(f\"\\nThreshold: {best_threshold:.4f}\")\n",
    "print(f\"F1: {final_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {final_auc.round(4)}\")\n",
    "\n",
    "# Store model in order to compare with best class-balanced model\n",
    "best_model.save_model(\"best_auto_weighted.cbm\")\n",
    "meta = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": best_threshold,\n",
    "    \"val_f1\": final_f1,\n",
    "    \"val_auc\": final_auc\n",
    "}\n",
    "with open(\"best_auto_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fbbec",
   "metadata": {},
   "source": [
    "## Model Selection and Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7e77f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics (used for selection):\n",
      "UNBALANCED: val_f1=0.6606, val_auc=0.8847, thr=0.28\n",
      "AUTO_WEIGHT: val_f1=0.6616, val_auc=0.8773, thr=0.49\n",
      "Retraining winner (auto_weighted) on full training set with its parameters: {'depth': 5, 'learning_rate': 0.006143977606332298, 'iterations': 2897, 'l2_leaf_reg': 2.8247969032742353e-06, 'random_seed': 12345, 'verbose': False, 'thread_count': -1, 'auto_class_weights': 'SqrtBalanced'}\n",
      "\n",
      "FINAL TEST EVALUATION:\n",
      "Winning Model: auto_weighted\n",
      "Test F1: 0.6526\n",
      "Test AUC: 0.8757\n",
      "Confusion Matrix:\n",
      "[[1459  134]\n",
      " [ 145  262]]\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "with open(\"best_unbalanced_meta.json\", \"r\") as f:\n",
    "    meta_un = json.load(f)\n",
    "with open(\"best_auto_meta.json\", \"r\") as f:\n",
    "    meta_au = json.load(f)\n",
    "\n",
    "# Load models\n",
    "unbal_model_file = \"best_unbalanced.cbm\"\n",
    "auto_model_file  = \"best_auto_weighted.cbm\"\n",
    "m_un = CatBoostClassifier(); m_un.load_model(unbal_model_file)\n",
    "m_au = CatBoostClassifier(); m_au.load_model(auto_model_file)\n",
    "\n",
    "# Extract the scores for comparison\n",
    "def val_metrics(meta):\n",
    "    return float(meta[\"val_f1\"]), float(meta[\"val_auc\"]), float(meta[\"threshold\"])\n",
    "\n",
    "f1_un, auc_un, thr_un = val_metrics(meta_un)\n",
    "f1_au, auc_au, thr_au = val_metrics(meta_au)\n",
    "\n",
    "print(\"Optimized Model Comparison:\")\n",
    "print(f\" UNBALANCED: val_f1={f1_un:.4f}, val_auc={auc_un:.4f}\")\n",
    "print(f\"AUTO_WEIGHT: val_f1={f1_au:.4f}, val_auc={auc_au:.4f}\")\n",
    "\n",
    "# Select winner through F1 score and tie-breaker AUC\n",
    "if f1_un > f1_au:\n",
    "    winner_key = \"unbalanced\"\n",
    "    winner_model_file = unbal_model_file\n",
    "    winner_meta = meta_un\n",
    "elif f1_au > f1_un:\n",
    "    winner_key = \"auto_weighted\"\n",
    "    winner_model_file = auto_model_file\n",
    "    winner_meta = meta_au\n",
    "else:\n",
    "    # Tiebreaker\n",
    "    if auc_un >= auc_au:\n",
    "        winner_key = \"unbalanced\"\n",
    "        winner_model_file = unbal_model_file\n",
    "        winner_meta = meta_un\n",
    "    else:\n",
    "        winner_key = \"auto_weighted\"\n",
    "        winner_model_file = auto_model_file\n",
    "        winner_meta = meta_au\n",
    "\n",
    "# Build full training set for final training\n",
    "X_train_all = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_all = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "win_params = winner_meta[\"params\"]\n",
    "\n",
    "# Extract parameters of the winning model\n",
    "cb_kwargs = {\n",
    "    \"depth\": int(win_params[\"depth\"]),\n",
    "    \"learning_rate\": float(win_params[\"learning_rate\"]),\n",
    "    \"iterations\": int(win_params[\"iterations\"]),\n",
    "    \"l2_leaf_reg\": float(win_params[\"l2_leaf_reg\"]),\n",
    "    \"random_seed\": RND,\n",
    "    \"verbose\": False,\n",
    "    \"thread_count\": -1\n",
    "}\n",
    "\n",
    "# If the auto-weighted model wins\n",
    "if \"auto_class_weights\" in win_params:\n",
    "    cb_kwargs[\"auto_class_weights\"] = win_params[\"auto_class_weights\"]\n",
    "\n",
    "print(f\"\\nRetraining winner ({winner_key}) on full training set with its parameters:\")\n",
    "for k, v in cb_kwargs.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"  threshold: {round(final_thr, 2)}\")\n",
    "\n",
    "# Retrain final model on full training data\n",
    "final_model = CatBoostClassifier(**cb_kwargs)\n",
    "final_model.fit(X_train_all, y_train_all, cat_features=cat_feat)\n",
    "\n",
    "# Evaluate final model on test set\n",
    "final_thr = float(winner_meta[\"threshold\"])\n",
    "final_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "final_pred = (final_proba >= final_thr).astype(int)\n",
    "\n",
    "final_f1 = f1_score(y_test, final_pred)\n",
    "final_auc = roc_auc_score(y_test, final_proba)\n",
    "\n",
    "print(\"\\nFINAL TEST EVALUATION:\")\n",
    "print(f\"Winning Model: {winner_key}\")\n",
    "print(f\"Test F1: {final_f1:.4f}\")\n",
    "print(f\"Test AUC: {final_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8ef172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>18.659882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NumOfProductsCAT</td>\n",
       "      <td>15.741442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balance</td>\n",
       "      <td>14.932290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geography</td>\n",
       "      <td>12.331644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CreditScore</td>\n",
       "      <td>8.909181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EstimatedSalary</td>\n",
       "      <td>8.453061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TenureCAT</td>\n",
       "      <td>7.476240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IsActiveMember</td>\n",
       "      <td>4.324035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tenure</td>\n",
       "      <td>3.455779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumOfProducts</td>\n",
       "      <td>2.962980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gender</td>\n",
       "      <td>2.230901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HasCrCard</td>\n",
       "      <td>0.522565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "0                Age   18.659882\n",
       "1   NumOfProductsCAT   15.741442\n",
       "2            Balance   14.932290\n",
       "3          Geography   12.331644\n",
       "4        CreditScore    8.909181\n",
       "5    EstimatedSalary    8.453061\n",
       "6          TenureCAT    7.476240\n",
       "7     IsActiveMember    4.324035\n",
       "8             Tenure    3.455779\n",
       "9      NumOfProducts    2.962980\n",
       "10            Gender    2.230901\n",
       "11         HasCrCard    0.522565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output feature importance of final model\n",
    "feat_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": final_model.get_feature_importance(type='PredictionValuesChange')\n",
    "}).sort_values(by=\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(feat_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72128168",
   "metadata": {},
   "source": [
    "- How long with bank?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
